<!DOCTYPE html><html><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><title>CS5340 notes</title><meta name="viewport" content="width=device-width, initial-scale=1"/><meta charSet="utf-8"/><meta name="next-head-count" content="3"/><link rel="preload" href="/cs5340-notes/_next/static/css/5dfbbaffc35a800d.css" as="style"/><link rel="stylesheet" href="/cs5340-notes/_next/static/css/5dfbbaffc35a800d.css" data-n-g=""/><link rel="preload" href="/cs5340-notes/_next/static/css/aa6e13e06d9ee8bf.css" as="style"/><link rel="stylesheet" href="/cs5340-notes/_next/static/css/aa6e13e06d9ee8bf.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/cs5340-notes/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/cs5340-notes/_next/static/chunks/webpack-1a9dadd301259fc4.js" defer=""></script><script src="/cs5340-notes/_next/static/chunks/framework-bbce3cdc1a611f18.js" defer=""></script><script src="/cs5340-notes/_next/static/chunks/main-fc964b5c4c532f0f.js" defer=""></script><script src="/cs5340-notes/_next/static/chunks/pages/_app-d9db60601a769715.js" defer=""></script><script src="/cs5340-notes/_next/static/chunks/pages/index-96185882f5940fd4.js" defer=""></script><script src="/cs5340-notes/_next/static/-d3_77Ycgj1Kg_UuYsx6M/_buildManifest.js" defer=""></script><script src="/cs5340-notes/_next/static/-d3_77Ycgj1Kg_UuYsx6M/_ssgManifest.js" defer=""></script><script src="/cs5340-notes/_next/static/-d3_77Ycgj1Kg_UuYsx6M/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout"><main class="Layout_layout-container__3q6VY"><nav class="Layout_navbar__Kc20I"><ul><li><a href="/cs5340-notes">Home</a></li><li><a target="_blank" href="https://github.com/picasdan9/cs5340-notes">Github</a></li></ul><div class="Layout_contents__gjF6O"><div class="Layout_contents-header__1QdYT">Contents</div><ol><li><a href="l2-bayesian-networks">Bayesian Networks (Directed Graphical Models)</a></li><li><a href="l3-mrf">Markov Random Fields (Undirected Graphical Models)</a></li><li><a href="l4-variable-elimination-and-belief-propagation">Variable Elimination and Belief Propogation</a></li><li><a href="l5-factor-graph-and-jt-algo">Factor Graph and Junction Tree Algorithm</a></li><li><a href="l6-parameter-learning-with-complete-data">Parameter Learning with Complete Data</a></li><li><a href="l7-mixture-models-and-em-algo">Mixture Models and the EM Algorithm</a></li><li><a href="l8-hmm">Hidden Markov Models (HMMs)</a></li><li><a href="l9-monte-carlo-inference">Monte Carlo Inference (Sampling)</a></li><li><a href="l10-variational-inference">Variational Inference</a></li><li><a href="l11-variational-autoencoder-and-mixture-density-networks">Variational Autoencoder and Mixture Density Networks</a></li><li><a href="l12-graph-cut-and-alpha-expansion">Graph-Cut and Alpha-Expansion</a></li></ol></div></nav><div class="Layout_page-container__Imgv6"><h1>CS5340 notes</h1><div>Dan N. Tran</div><section><p>This site is my notes for the NUS course CS5340. The notes are compiled from various textbooks and lecture/course notes on the topic of probabilistic graphical modelling (PGM). Relevant source materials are credited at the end of each page in this site.</p><p>The content and organisation of the topics closely follow the course as taught by Prof. Lee Gim Hee in AY2021-22 Semester 1.</p><p>For any feedback or query, contact me at<!-- --> <a href="mailto: dann.tran@u.nus.edu">dann.tran@u.nus.edu</a>.</p></section><section class="Home_contents__2n1qN"><h2>Table of Contents</h2><ol><li><a href="l2-bayesian-networks">Bayesian Networks (Directed Graphical Models)</a><div class="Home_tags__GdMop">representation</div></li><li><a href="l3-mrf">Markov Random Fields (Undirected Graphical Models)</a><div class="Home_tags__GdMop">representation</div></li><li><a href="l4-variable-elimination-and-belief-propagation">Variable Elimination and Belief Propogation</a><div class="Home_tags__GdMop">inference</div></li><li><a href="l5-factor-graph-and-jt-algo">Factor Graph and Junction Tree Algorithm</a><div class="Home_tags__GdMop">representation, inference</div></li><li><a href="l6-parameter-learning-with-complete-data">Parameter Learning with Complete Data</a><div class="Home_tags__GdMop">learning</div></li><li><a href="l7-mixture-models-and-em-algo">Mixture Models and the EM Algorithm</a><div class="Home_tags__GdMop">learning</div></li><li><a href="l8-hmm">Hidden Markov Models (HMMs)</a><div class="Home_tags__GdMop">modelling, inference, learning</div></li><li><a href="l9-monte-carlo-inference">Monte Carlo Inference (Sampling)</a><div class="Home_tags__GdMop">inference</div></li><li><a href="l10-variational-inference">Variational Inference</a><div class="Home_tags__GdMop">inference</div></li><li><a href="l11-variational-autoencoder-and-mixture-density-networks">Variational Autoencoder and Mixture Density Networks</a><div class="Home_tags__GdMop">modelling, inference, learning</div></li><li><a href="l12-graph-cut-and-alpha-expansion">Graph-Cut and Alpha-Expansion</a><div class="Home_tags__GdMop">modelling, learning, inference</div></li></ol></section></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"metadataList":[{"slug":"l2-bayesian-networks","title":"Bayesian Networks (Directed Graphical Models)","tags":"representation","lectureNumber":2},{"slug":"l3-mrf","title":"Markov Random Fields (Undirected Graphical Models)","tags":"representation","lectureNumber":3},{"slug":"l4-variable-elimination-and-belief-propagation","title":"Variable Elimination and Belief Propogation","tags":"inference","lectureNumber":4},{"slug":"l5-factor-graph-and-jt-algo","title":"Factor Graph and Junction Tree Algorithm","tags":"representation, inference","lectureNumber":5},{"slug":"l6-parameter-learning-with-complete-data","title":"Parameter Learning with Complete Data","tags":"learning","lectureNumber":6},{"slug":"l7-mixture-models-and-em-algo","title":"Mixture Models and the EM Algorithm","tags":"learning","lectureNumber":7},{"slug":"l8-hmm","title":"Hidden Markov Models (HMMs)","tags":"modelling, inference, learning","lectureNumber":8},{"slug":"l9-monte-carlo-inference","title":"Monte Carlo Inference (Sampling)","tags":"inference","lectureNumber":9},{"slug":"l10-variational-inference","title":"Variational Inference","tags":"inference","lectureNumber":10},{"slug":"l11-variational-autoencoder-and-mixture-density-networks","title":"Variational Autoencoder and Mixture Density Networks","tags":"modelling, inference, learning","lectureNumber":11},{"slug":"l12-graph-cut-and-alpha-expansion","title":"Graph-Cut and Alpha-Expansion","tags":"modelling, learning, inference","lectureNumber":12}]},"__N_SSG":true},"page":"/","query":{},"buildId":"-d3_77Ycgj1Kg_UuYsx6M","assetPrefix":"/cs5340-notes","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>